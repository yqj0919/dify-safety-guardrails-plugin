identity:
  name: "safety_guardrails"
  author: "yuanquanjiang"
  label:
    en_US: "Safety Guardrails"
    zh_Hans: "安全护栏"
    pt_BR: "Safety Guardrails"
    ja_JP: "セーフティガードレール"
description:
  human:
    en_US: "AI safety guardrails system that provides pre-filtering and post-filtering to defend against malicious attacks and ensure generated content is safe and compliant. Includes prompt injection detection, content value review, and sensitive data checking."
    zh_Hans: "大模型安全护栏是一套无需修改模型本身、通过前置审核与后置过滤来防御恶意攻击并确保生成内容安全合规的外部防护系统。包括提示词攻击、内容价值观审核、敏感数据检查。"
    pt_BR: "Sistema de proteção de segurança de IA que fornece pré-filtragem e pós-filtragem para defender contra ataques maliciosos e garantir que o conteúdo gerado seja seguro e compatível."
    ja_JP: "悪意のある攻撃を防御し、生成されたコンテンツが安全で準拠していることを保証するための事前フィルタリングと事後フィルタリングを提供するAI安全ガードレールシステム。"
  llm: "AI safety guardrails system for content auditing and security filtering. Input content to check for safety compliance, prompt injection attacks, and sensitive information."
parameters:
  - name: query
    type: string
    required: true
    label:
      en_US: Content to Audit
      zh_Hans: 待审核内容
      pt_BR: Conteúdo para Auditoria
      ja_JP: 監査対象コンテンツ
    human_description:
      en_US: "Enter the text content you want to audit for safety compliance. The system will check for potential security risks, inappropriate content, and policy violations."
      zh_Hans: "输入您要进行安全合规审核的文本内容。系统将检查潜在的安全风险、不当内容和政策违规。"
      pt_BR: "Digite o conteúdo de texto que você deseja auditar para conformidade de segurança. O sistema verificará possíveis riscos de segurança, conteúdo inadequado e violações de política."
      ja_JP: "安全コンプライアンスの監査を行いたいテキストコンテンツを入力してください。システムは潜在的なセキュリティリスク、不適切なコンテンツ、ポリシー違反をチェックします。"
    llm_description: "Text content to be audited for safety, security risks, and compliance with content policies."
    form: llm
extra:
  python:
    source: tools/safety_guardrails.py
